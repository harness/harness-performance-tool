
## Harness Performance Test Report - 08'JULY 2024

This document details information about following :
1. Test Environment and resource configuration
2. Test scenario and results

### [Environment](#)
- GKE (Kubernetes Server Version) : 1.28.x

### [Database](#)
- Mongo Atlas M60

### [Redis](#)
- GCP Memory Store (11 GB)

### [Harness Services](#)

Helm chart : https://github.com/harness/helm-charts/releases/tag/harness-0.18.0

| Service Name             | Replicas | CPU (per replica) | Memory (per replica) |    Version     |
|--------------------------|:--------:|:-----------------:|:--------------------:|:--------------:|
| access-control           |    4     |         1         |          5           | harness-0.18.0 |
| ci-manager               |    4     |         3         |          6           | harness-0.18.0 |
| pipeline-service         |    7     |         4         |          10          | harness-0.18.0 |
| manager                  |    7     |         3         |          12          | harness-0.18.0 |
| log-service              |    3     |         3         |          12          | harness-0.18.0 |
| ng-manager               |    6     |         2         |          6           | harness-0.18.0 |
| scm                      |    2     |        0.5        |          1           | harness-0.18.0 |
| gateway                  |    5     |         1         |          4           | harness-0.18.0 |
| default-backend          |    1     |        0.1        |         0.2          | harness-0.18.0 |
| nginx-ingress-controller |    1     |         5         |          10          | harness-0.18.0 |
| change-data-capture      |    1     |         4         |          6           | harness-0.18.0 |
| next-gen-ui              |    2     |        0.5        |         0.5          | harness-0.18.0 |
| ng-auth-ui               |    2     |        0.1        |         0.1          | harness-0.18.0 |
| platform-service         |    2     |        0.5        |          3           | harness-0.18.0 |
| template-service         |    2     |         1         |          8           | harness-0.18.0 |
| sto-core                 |    4     |        0.5        |         1.5          | harness-0.18.0 |
| sto-manager              |    2     |         3         |          6           | harness-0.18.0 |
| ui                       |    3     |        0.1        |         0.5          | harness-0.18.0 |
| policy-mgmt              |    3     |        0.3        |          1           | harness-0.18.0 |
| timescaledb              |    2     |         1         |          2           | harness-0.18.0 |
| ng-dashboard-aggregator  |    2     |       0.25        |          2           | harness-0.18.0 |

#### Override file : https://github.com/harness/helm-charts/blob/main/src/harness/override-perf.yaml

### [Test Scenarios](#)
  
#### [ >  3000 concurrent CI Executions [INLINE]](#)
Each CI pipeline would 
- initialise a k8s pod and git clone repo  
- run 5 parallel steps (100 sec sleep)
- run template with 2 parallel steps (140sec sleep)

Projects : 1  
Pipelines : 3000  
Stages per pipeline : 1  
Delegates : 15 (1cpu/4gi)  
Trigger type : webhook  
Test class : [CI_PIPELINE_WEBHOOK_RUN](../locust_tasks/ci_pipeline_webhook_run.py)

> Result : **PASS**  
Avg Execution Time: **6min 36sec**
  
#### [ >  2300 concurrent CD Executions [INLINE]](#)
Each CD pipeline would 
- fetch docker artifact from AWS ECR repo
- run following steps in order:
   - Canary deploy
   - Canary delete
   - Rolling deploy
   - K8s Delete

Projects : 1  
Pipelines : 2300  
Stages per pipeline : 1   
Delegates : 60 (1cpu/4gi)  
Test class : [CD_PIPELINE_WEBHOOK_RUN](../locust_tasks/cd_pipeline_webhook_run.py)

> Result : **PASS**  
Avg Execution Time: **6min 4sec**

