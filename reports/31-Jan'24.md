
## Harness Performance Test Report - 31'JAN 2024

This document details information about following :
1. Test Environment and resource configuration
2. Test scenario and results

### [Environment](#)
- GKE (Kubernetes Version) : 1.25.x 

### [Database](#)
- Mongo Atlas M60

### [Redis](#)
- GCP Memory Store (11 GB)

### [Harness Services](#)

Helm chart : https://github.com/harness/helm-charts/releases/tag/harness-0.13.0

| Service Name             | Replicas | CPU (per replica) | Memory (per replica) |    Version     |
|--------------------------|:--------:|:-----------------:|:--------------------:|:--------------:|
| access-control           |    4     |         1         |          5           | harness-0.13.0 |
| ci-manager               |    4     |         3         |          6           | harness-0.13.0 |
| pipeline-service         |    7     |         4         |          10          | harness-0.13.0 |
| manager                  |    7     |         3         |          12          | harness-0.13.0 |
| log-service              |    3     |         3         |          12          | harness-0.13.0 |
| ng-manager               |    5     |         2         |          6           | harness-0.13.0 |
| scm                      |    2     |        0.5        |          1           | harness-0.13.0 |
| gateway                  |    5     |         1         |          4           | harness-0.13.0 |
| default-backend          |    1     |        0.1        |         0.2          | harness-0.13.0 |
| nginx-ingress-controller |    1     |         5         |          10          | harness-0.13.0 |
| change-data-capture      |    1     |         4         |          6           | harness-0.13.0 |
| next-gen-ui              |    2     |        0.5        |         0.5          | harness-0.13.0 |
| ng-auth-ui               |    2     |        0.1        |         0.1          | harness-0.13.0 |
| platform-service         |    2     |        0.5        |          3           | harness-0.13.0 |
| template-service         |    2     |         1         |          8           | harness-0.13.0 |
| ti-service               |    2     |         1         |          6           | harness-0.13.0 |
| sto-core                 |    4     |        0.5        |         1.5          | harness-0.13.0 |
| sto-manager              |    2     |         3         |          6           | harness-0.13.0 |
| gitops                   |    2     |         2         |          2           | harness-0.13.0 |
| ui                       |    3     |        0.1        |         0.5          | harness-0.13.0 |
| policy-mgmt              |    3     |        0.3        |          1           | harness-0.13.0 |
| timescaledb              |    2     |         1         |          2           | harness-0.13.0 |
| verification-svc         |    2     |        0.3        |          4           | harness-0.13.0 |
| ng-dashboard-aggregator  |    2     |       0.25        |          2           | harness-0.13.0 |

#### Override file : https://github.com/harness/helm-charts/blob/main/src/harness/override-perf.yaml

### [Test Scenarios](#)
  
#### [ >  2000 concurrent CI Executions [INLINE]](#)
Each CI pipeline would 
- initialise a k8s pod and git clone repo  
- run 5 parallel steps (100 sec sleep)
- run template with 2 parallel steps (140sec sleep)

Projects : 1  
Pipelines : 2000  
Stages per pipeline : 1  
Delegates : 15 (1cpu/4gi)  
Trigger type : webhook  
Test class : [CI_PIPELINE_WEBHOOK_RUN](../locust_tasks/ci_pipeline_webhook_run.py)

> Result : **PASS**  
Avg Execution Time: **6.5min**
  
#### [ >  1500 concurrent CI Executions [GitX]](#)
Each CI pipeline would 
- initialise a k8s pod and git clone repo
- run 5 parallel steps (360 sec sleep) and echo statements

Projects : 1  
Pipelines : 1500  
Stages per pipeline : 1  
Delegates : 15 (1cpu/2gi)  
Trigger type : webhook  
Test class : [CI_PIPELINE_REMOTE_RUN](../locust_tasks/ci_pipeline_remote_run.py)

> Result : **PASS**  
Avg Execution Time: **8.5min**
  
#### [ >  1000 concurrent CD Executions [INLINE]](#)
Each CD pipeline would 
- fetch docker artifact from AWS ECR repo
- run following steps in order:
   - Canary deploy
   - Canary delete
   - Rolling deploy
   - K8s Delete

Projects : 1  
Pipelines : 1000  
Stages per pipeline : 1   
Delegates : 26 (1cpu/4gi)  
Test class : [CD_PIPELINE_RUN](../locust_tasks/cd_pipeline_run.py)

> Result : **PASS**  
Avg Execution Time: **4.5min**

